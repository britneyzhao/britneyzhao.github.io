---
layout: post
title: Blog Post 3 - Analyzing Fake News with Tensorflow
---

This blog post will explain how create a model to identify fake news using Tensorflow. 

## Acquire Training Data

First, this model uses lots of modules, so let's import them and explain their use:

```python
import numpy as np
import pandas as pd
import tensorflow as tf
import re #regular expressions
import string

from tensorflow.keras import layers #creating layers
from tensorflow.keras import losses #loss functions
from tensorflow import keras

from tensorflow.keras.layers.experimental.preprocessing import TextVectorization
from tensorflow.keras.layers.experimental.preprocessing import StringLookup

# for embedding viz
import plotly.express as px 
import plotly.io as pio
pio.templates.default = "plotly_white"
```

Overall, we have a little bit to unpack here, but we'll mainly be using the following modules for various reasons: 
- `numpy`: to manipulate arrays in a convenient way
- `pandas`: to create dataframes
- `tensorflow`: to implement machine learning techniques
    - `layers` is for creating layers in our algorithm
    - `losses` is for loss functions
- `re`: for creating regular expressions for string recognition 
- `string`: for manipulating strings
- `plotly`: for ploting visualizations of our data

With these modules, let's first acquire our training data! For this project, we want to ultimately create a model that can accurately determine if a news article is fake or not. To do so, we will need some data to train our model. This training data contains information about the title of the article, text from the article, and whether it is fake or not. Let's use `pd.read_csv()` to first obtain this data: 

```python
train_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true"

df = pd.read_csv(train_url)
df
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>title</th>
      <th>text</th>
      <th>fake</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>17366</td>
      <td>Merkel: Strong result for Austria's FPO 'big c...</td>
      <td>German Chancellor Angela Merkel said on Monday...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5634</td>
      <td>Trump says Pence will lead voter fraud panel</td>
      <td>WEST PALM BEACH, Fla.President Donald Trump sa...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>17487</td>
      <td>JUST IN: SUSPECTED LEAKER and “Close Confidant...</td>
      <td>On December 5, 2017, Circa s Sara Carter warne...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>12217</td>
      <td>Thyssenkrupp has offered help to Argentina ove...</td>
      <td>Germany s Thyssenkrupp, has offered assistance...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5535</td>
      <td>Trump say appeals court decision on travel ban...</td>
      <td>President Donald Trump on Thursday called the ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>22444</th>
      <td>10709</td>
      <td>ALARMING: NSA Refuses to Release Clinton-Lynch...</td>
      <td>If Clinton and Lynch just talked about grandki...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>22445</th>
      <td>8731</td>
      <td>Can Pence's vow not to sling mud survive a Tru...</td>
      <td>() - In 1990, during a close and bitter congre...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>22446</th>
      <td>4733</td>
      <td>Watch Trump Campaign Try To Spin Their Way Ou...</td>
      <td>A new ad by the Hillary Clinton SuperPac Prior...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>22447</th>
      <td>3993</td>
      <td>Trump celebrates first 100 days as president, ...</td>
      <td>HARRISBURG, Pa.U.S. President Donald Trump hit...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>22448</th>
      <td>12896</td>
      <td>TRUMP SUPPORTERS REACT TO DEBATE: “Clinton New...</td>
      <td>MELBOURNE, FL is a town with a population of 7...</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>22449 rows × 4 columns</p>
</div>

In this dataframe, the `fake` column will have `0` represent if an article is true, and `1` if the article contains fake news. Now, we have lots of data to train our model with! 

## Make a Dataset

Now that we have the data that we want to analyze, we'll need to first create a dataset that Tensorflow will be able to interpret. To do so, let's create a function `make_dataset()` that will both clean our data and compile it into this dataset. 

For cleaning our data, we want to remove all *stopwords* from it, or words that are usually uninformative, such as "the" or "and." To recognize these words, we'll use the list of stopwords from the module `ntlk`. Essentially, we want to go through every word in the title and text of each article, remove it if it's a stopword, then create our dataset with these cleaned data. 

We want to have the model observe the title and text of the article, then predict if the article has fake information in it or not. Therefore, we want to create a dataset in the form like so: `(input, output)`. We'll use a tuple of dictionaries to do this, so the "title" of an article is associated with the `title` column of the dataframe `df` from before. All together, the code should look like so: 

```python
#import list of stopwords
import nltk
nltk.download('stopwords')
stop = stopwords.words('english')

def make_dataset(df):
  #remove stopwords
  df['title'] = df['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))
  df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))

  #create dataset
  data = tf.data.Dataset.from_tensor_slices(
      (
        {
            "title" : df[['title']],
            "text" : df[['text']]
        },
       {
            "fake" : df[['fake']]   
       }
      )
  )
  data.batch(100)
  return data
```

Great! Now we have a function that takes in a `pandas` dataframe and returns a Tensorflow dataset that we can use for our machine learning algorithm. With this function, let's create our dataset for this example: 

```python
data = make_dataset(df)
```

Now that we have the dataset, we want to split our data into two different parts: training and validation. Majority of the data will be used for training, since that's what we need to create a proper model! The validation data will be used as new pieces of data that the model hasn't seen to see how it responds at a certain round of training. For this example, we'll have 80% training data and 20% validation data overall. Since our dataset is quite large, we'll compile it into batches of 20 to make it more efficient. All together, we can split it up like so: 

```python
train_size = int(0.8*len(data))

train = data.take(train_size).batch(20)
val = data.skip(train_size).batch(20)
```

We now have data to create a model with! 

## Model Creation

Let's create three different models to see which analyzes the articles the best! One will use the article's title, one will use the article's text, and our final one will use both the title and text. To do so, we'll use the following process:
1. Create input that Tensorflow can interpret
2. Process the input information and vectorize it so that the algorithm can understand it 
3. Create each layer of the fake news identifier, which will ultimately become our model
4. Compile the model 
5. Train the model using our data from before


